{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanter\n",
    "\n",
    "LIMIT_AXLES_SAME_GROUP = 1.8\n",
    "AXLE_WEIGHT = 'AxleWeight'\n",
    "AXLE_DISTANCE = 'AxleDistance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_axle_load_distribution(filepath: str) -> tuple:\n",
    "    single_axle = np.array([])\n",
    "    boggi_axle = np.array([])\n",
    "    triple_axle = np.array([])\n",
    "\n",
    "    df = pl.read_csv(filepath, separator=';', truncate_ragged_lines=True, skip_rows=6, ignore_errors=True)\n",
    "    df = df.filter(pl.col('GrossWeight') > 3500)\n",
    "\n",
    "    for row in df.iter_rows(named=True):\n",
    "        single, boggi, triple = calculate_axle_load_distribution_vehicle(row)\n",
    "        single_axle = np.concatenate((single_axle, single))\n",
    "        boggi_axle = np.concatenate((boggi_axle, boggi))\n",
    "        triple_axle = np.concatenate((triple_axle, triple))\n",
    "\n",
    "    return single_axle, boggi_axle, triple_axle\n",
    "\n",
    "\n",
    "def calculate_axle_load_distribution_vehicle(row: tuple) -> tuple:\n",
    "    single_axle = np.array([])\n",
    "    boggi_axle = np.array([])\n",
    "    triple_axle = np.array([])\n",
    "\n",
    "    def distribute_weight(axles_in_group, weight_in_group):\n",
    "        nonlocal single_axle, boggi_axle, triple_axle\n",
    "        if axles_in_group == 1:\n",
    "            single_axle = np.append(single_axle, weight_in_group)\n",
    "        elif axles_in_group == 2:\n",
    "            boggi_axle = np.append(boggi_axle, weight_in_group)\n",
    "        elif axles_in_group == 3:\n",
    "            triple_axle = np.append(triple_axle, weight_in_group)\n",
    "\n",
    "    def axle_information(row: tuple, axle: int) -> tuple:\n",
    "        try:\n",
    "            has_axle_syntax_1 = f'{AXLE_DISTANCE}{axle}' in row and row[f'{AXLE_DISTANCE}{axle}'] != None\n",
    "            has_axle_syntax_2 = f'{AXLE_DISTANCE} {axle}' in row and row[f'{AXLE_DISTANCE} {axle}'] != None\n",
    "\n",
    "            if has_axle_syntax_1:\n",
    "                return True, float(row[f'{AXLE_DISTANCE}{axle}']), float(row[f'{AXLE_WEIGHT}{axle}']) / 1000\n",
    "            elif has_axle_syntax_2:\n",
    "                return True, float(row[f'{AXLE_DISTANCE} {axle}']), float(row[f'{AXLE_WEIGHT} {axle}']) / 1000\n",
    "        except:\n",
    "            # Støter på problemer her med at csv filene tolker data som datoer, får opp typ apr.33 etc,\n",
    "            # velger dermed å droppe kranglete akseldata\n",
    "            pass \n",
    "\n",
    "        return False, None, None\n",
    "\n",
    "    axle = 1\n",
    "    axles_in_group = 0\n",
    "    weight_in_group = 0\n",
    "\n",
    "    while True:\n",
    "        has_axle, distance_from_previous_axle, weight_axle = axle_information(row, axle)\n",
    "        if not has_axle:\n",
    "            break\n",
    "\n",
    "        if distance_from_previous_axle <= LIMIT_AXLES_SAME_GROUP:\n",
    "            axles_in_group += 1\n",
    "            weight_in_group += weight_axle\n",
    "\n",
    "        else:\n",
    "            distribute_weight(axles_in_group, weight_in_group)\n",
    "                \n",
    "            axles_in_group = 1\n",
    "            weight_in_group = weight_axle\n",
    "\n",
    "        axle += 1\n",
    "\n",
    "    distribute_weight(axles_in_group, weight_in_group)\n",
    "        \n",
    "    return single_axle, boggi_axle, triple_axle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = (\n",
    "    '../WIM-data/Kistler_Øysand/20160808-31_Kistler Øysand_4913151-export(1).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20160901-30_Kistler Øysand_4913151-export(2).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20161001-31_Kistler Øysand_4913151-export(3)-fixed.csv',\n",
    "    '../WIM-data/Kistler_Øysand/20161101-30_Kistler Øysand_4913151-export(4).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20161201-31_Kistler Øysand_4913151-export(5).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20170101-31_Kistler Øysand_4913151-export(6).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20170201-28_Kistler Øysand_4913151-export(7).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20170301-31_Kistler Øysand_4913151-export(8).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20170401-05_Kistler Øysand_4913151-export(9)-fixed.csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180316_1.3.1_Kistler Øysand_4913151-export(24).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180401-30_Kistler Øysand_4796227-export(12).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180501-31(21-26)_Kistler Øysand_4796227-export(13).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180601-30(11-30)_Kistler Øysand_4796227-export(14).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180701-31(01-11)_Kistler Øysand_4796227-export(15).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180801-31(10-31)_Kistler Øysand_4796227-export(16).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180901-30_Kistler Øysand 4796227-export(17).csv',\n",
    "    '../WIM-data/Kistler_Skibotn/combinedFiles_E8_2018_kalibrert_4okt.csv',\n",
    "    '../WIM-data/Kistler_Skibotn/combinedFiles_E8_2019.csv',\n",
    "    '../WIM-data/Kistler_Skibotn/combinedFiles_E8_2020.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150513-20150531_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150601-20150630_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150701-20150731_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150801-20150831_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150901-20150930_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20151001-20151031_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20151101-20151130_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20151201-20151231_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160101-20160131_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160201-20160229_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160301-20160331_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160401-20160430_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160501-20160531_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20221014-20 Kistler_R3_ostg.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20221014-20 Kistler_R3_vestg.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20231001-20240123_Aanestad_Ostgående.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20231001-20240123_Aanestad_Vestgående.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(plot=True):\n",
    "    '''\n",
    "    Plotter dersom plot=True, ellers lagrer den heller plots'ene som bilder\n",
    "    '''\n",
    "\n",
    "    n_rows = len(datasets)\n",
    "    n_cols = 3\n",
    "    data_information = ('Enkeltaksler', 'Boggiaksler', 'Trippelaksler')\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4.5 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "    ax_index = -1\n",
    "\n",
    "    for dataset in datasets:\n",
    "        name_dataset = dataset.split('/')[-1]\n",
    "        axle_load_distribution = calculate_axle_load_distribution(dataset)\n",
    "\n",
    "        for i in range(0, 3):\n",
    "            data = axle_load_distribution[i]\n",
    "            mean = np.mean(data)\n",
    "            median = np.median(data)\n",
    "            ax_index += 1\n",
    "            ax = axes[ax_index]\n",
    "            ax.hist(data, bins=100, color='blue', edgecolor='black')\n",
    "            ax.set_xlabel('Akselvekt (tonn)')\n",
    "            ax.set_ylabel('Passeringer')\n",
    "            ax.set_title(f'Dataset: {name_dataset}\\nAkselgruppe: {data_information[i]}', fontsize=10)\n",
    "            ax.text(0.5, -0.15, f'Snitt: {mean:.2f} | Median: {median:.2f}', ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        output_dir = 'aksellastfordelinger'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        for i, ax in enumerate(axes):\n",
    "            row = i // n_cols\n",
    "            col = i % n_cols\n",
    "            dataset_name = datasets[row].split('/')[-1].replace('.csv', '')\n",
    "            data_type = data_information[col]\n",
    "            filename = f'{output_dir}/{dataset_name}_{data_type}.png'\n",
    "            fig.savefig(filename)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plot=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
