{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import mercury as mr\n",
    "import os\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "from datetime import datetime, timedelta\n",
    "from tabulate import tabulate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanter\n",
    "\n",
    "TIME = 'StartTimeStr'\n",
    "STARTDATE = 'StartDate'\n",
    "AXLES_COUNT = 'AxlesCount'\n",
    "AXLE_WEIGHT = 'AxleWeight'\n",
    "STARTTIME_UNIX = 'StartTime'\n",
    "AXLE_DISTANCE = 'AxleDistance'\n",
    "VEHICLE_LENGTH = 'VehicleLength'\n",
    "LIMIT_AXLES_SAME_GROUP = 1.8\n",
    "OLD_LIMIT_HEAVY_VEHICLE = 5.6\n",
    "NEW_LIMIT_HEAVY_VEHICLE = 7.5\n",
    "MILLISECONDS_IN_YEAR = 1000 * 60 * 60 * 24 * 365\n",
    "P = 1  # P er forventet årlig trafikkvekst for tunge kjøretøy, antar her at trafikkveksten holder seg konstant\n",
    "\n",
    "def determine_f(dataset):\n",
    "    if 'Øysand' in dataset:\n",
    "        return 0.5 # antar 2-feltsveg basert på google-streetview bilder fra området rundt øysand, vet ikke nøyaktig hvor sensoren er\n",
    "    if 'Skibotn' in dataset:\n",
    "        return 0.5 # antar 2-feltsveg basert på google-streetview bilder fra området rundt skibotn, vet ikke nøyaktig hvor sensoren er\n",
    "    if 'Verdal' in dataset:\n",
    "        return 0.5 # antar 2-feltsveg basert på google-streetview bilder fra området rundt verdal, vet ikke nøyaktig hvor sensoren er\n",
    "    if 'Aanestad' in dataset:\n",
    "        return 0.45 # antar 2-feltsveg basert på google-streetview bilder fra området rundt Ånestad, vet ikke nøyaktig hvor sensoren er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = (\n",
    "    '../WIM-data/Kistler_Øysand/20160808-31_Kistler Øysand_4913151-export(1).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20160901-30_Kistler Øysand_4913151-export(2).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20161001-31_Kistler Øysand_4913151-export(3)-fixed.csv',\n",
    "    '../WIM-data/Kistler_Øysand/20161101-30_Kistler Øysand_4913151-export(4).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20161201-31_Kistler Øysand_4913151-export(5).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20170101-31_Kistler Øysand_4913151-export(6).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20170201-28_Kistler Øysand_4913151-export(7).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20170301-31_Kistler Øysand_4913151-export(8).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20170401-05_Kistler Øysand_4913151-export(9)-fixed.csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180316_1.3.1_Kistler Øysand_4913151-export(24).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180401-30_Kistler Øysand_4796227-export(12).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180501-31(21-26)_Kistler Øysand_4796227-export(13).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180601-30(11-30)_Kistler Øysand_4796227-export(14).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180701-31(01-11)_Kistler Øysand_4796227-export(15).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180801-31(10-31)_Kistler Øysand_4796227-export(16).csv',\n",
    "    '../WIM-data/Kistler_Øysand/20180901-30_Kistler Øysand 4796227-export(17).csv',\n",
    "    '../WIM-data/Kistler_Skibotn/combinedFiles_E8_2018_kalibrert_4okt.csv',\n",
    "    '../WIM-data/Kistler_Skibotn/combinedFiles_E8_2019.csv',\n",
    "    '../WIM-data/Kistler_Skibotn/combinedFiles_E8_2020.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150513-20150531_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150601-20150630_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150701-20150731_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150801-20150831_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20150901-20150930_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20151001-20151031_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20151101-20151130_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20151201-20151231_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160101-20160131_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160201-20160229_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160301-20160331_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160401-20160430_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Verdal/20160501-20160531_Kistler Verdal 4796227.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20221014-20 Kistler_R3_ostg.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20221014-20 Kistler_R3_vestg.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20231001-20240123_Aanestad_Ostgående.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20231001-20240123_Aanestad_Vestgående.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20240122-20240612_R3 vestgående.csv',\n",
    "    '../WIM-data/Kistler_Aanestad/20240123-20240612_R3 østgående.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n(c, e, ådtt, f, p):\n",
    "    return 365 * c * e * ådtt * f * ((1 + 0.01 * p)**20 - 1) / (0.01 * p)\n",
    "\n",
    "def calculate_c(df: pl.DataFrame) -> float:\n",
    "    axles_heavy_vehicles = df.select(pl.col(AXLES_COUNT)).to_series().to_list()\n",
    "    axles_heavy_vehicles = np.array([int(axle) for axle in axles_heavy_vehicles])\n",
    "    n = len(axles_heavy_vehicles) \n",
    "    c = np.sum(axles_heavy_vehicles) / n\n",
    "\n",
    "    return c\n",
    "\n",
    "def calculate_e_and_b(df: pl.DataFrame) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Regner ut E (gjennomsnittlig ekvivalensfaktor for akslene på tunge kjøretøy) og B-faktor (gjennomsnittlig nedbrytende effekt).\n",
    "    Samlet i en funksjon etterom begge verdier baserer seg på summen av ESALS-verdier, som har blitt implementert med iterasjon gjennom \n",
    "    hver rad i datasettet (kostbar beregning; tar lang tid).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pl.DataFrame\n",
    "        Polars dataframe som det skal beregnes E og B-faktor for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    calculate_e_and_b : Tuple[float, float]\n",
    "        Float's som representerer E og B-faktor.\n",
    "    \"\"\"\n",
    "    \n",
    "    def calculate_esal_and_number_of_axel_groups(df: pl.DataFrame) -> float:\n",
    "\n",
    "        def calculate_esal_individual(row: tuple) -> float:\n",
    "\n",
    "            def k_value(axles: int) -> float:\n",
    "                return 1 if axles == 1 else (10 / (6 + 6 * axles))**4\n",
    "            \n",
    "            def row_has_axle(row, axle):\n",
    "                return (\n",
    "                        f'{AXLE_DISTANCE}{axle}' in row \n",
    "                    and row[f'{AXLE_DISTANCE}{axle}'] != None \n",
    "                    and row[f'{AXLE_WEIGHT}{axle}'] != None\n",
    "                )\n",
    "\n",
    "            def store_previous_axle_group(weight_in_group, axles_in_group):\n",
    "                nonlocal weights, k_values\n",
    "                weights = np.append(weights, weight_in_group)\n",
    "                k_values = np.append(k_values, k_value(axles_in_group))\n",
    "\n",
    "            weights = np.array([])\n",
    "            k_values = np.array([])\n",
    "\n",
    "            axle = 1\n",
    "            axles_in_group = 0\n",
    "            weight_in_group = 0\n",
    "\n",
    "            while row_has_axle(row, axle):\n",
    "\n",
    "                distance_from_previous_axle = float(row[f'{AXLE_DISTANCE}{axle}'])\n",
    "\n",
    "                if distance_from_previous_axle <= LIMIT_AXLES_SAME_GROUP:\n",
    "                    axles_in_group += 1\n",
    "                    weight_in_group += (float(row[f'{AXLE_WEIGHT}{axle}']) / 1000)\n",
    "\n",
    "                else:\n",
    "                    store_previous_axle_group(weight_in_group, axles_in_group)\n",
    "                    axles_in_group = 1\n",
    "                    weight_in_group = (float(row[f'{AXLE_WEIGHT}{axle}']) / 1000)\n",
    "\n",
    "                axle += 1\n",
    "\n",
    "            store_previous_axle_group(weight_in_group, axles_in_group)\n",
    "                \n",
    "            return weights, k_values\n",
    "\n",
    "        esal_values_individual_vehicles = np.array([])\n",
    "        number_of_axel_groups = 0 # ngrp, antall akselgrupper (dvs. enkeltaksler + boggiaksler + trippelaksler osv.)\n",
    "\n",
    "        for row in df.iter_rows(named=True):\n",
    "            weights, k_values = calculate_esal_individual(row)\n",
    "            esal_values_individual_vehicles = np.append(esal_values_individual_vehicles, np.sum((weights / 10)**4 * k_values))\n",
    "            number_of_axel_groups += len(weights)\n",
    "\n",
    "        return esal_values_individual_vehicles, number_of_axel_groups\n",
    "\n",
    "    esals, ngrp = calculate_esal_and_number_of_axel_groups(df) # ngrp er antall akselgrupper\n",
    "    sigma_esals = np.sum(esals)\n",
    "    nkjt = len(df) # antall kjøretøy\n",
    "\n",
    "    e = sigma_esals / ngrp\n",
    "    b = sigma_esals / nkjt\n",
    "\n",
    "    return e, b\n",
    "\n",
    "def calculate_ådtt(df: pl.DataFrame, start_daterange: datetime=None) -> float:\n",
    "\n",
    "    # dersom veiens åpningsdato ikke er eksplisitt definert benyttes den første registrerte verdien i filen\n",
    "    if start_daterange is None:\n",
    "        start_unix = df.select(pl.col(STARTTIME_UNIX).min()).to_numpy()[0, 0]\n",
    "    else:\n",
    "        start_unix = int(start_daterange.timestamp() * 1000)\n",
    "    end_unix = start_unix + MILLISECONDS_IN_YEAR\n",
    "\n",
    "    heavy_vehicles_first_year = df.filter(\n",
    "        (pl.col(STARTTIME_UNIX) >= start_unix) & \n",
    "        (pl.col(STARTTIME_UNIX) <= end_unix)\n",
    "    )\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col(STARTTIME_UNIX)\n",
    "            .map_elements(\n",
    "                lambda ts: datetime.fromtimestamp(int(ts) / 1000).strftime('%Y-%m-%d'), \n",
    "                return_dtype=pl.String\n",
    "            )\n",
    "        ).alias(STARTDATE)\n",
    "    )\n",
    "    \n",
    "    unique_days_in_range = df.select(pl.col(STARTDATE)).n_unique()\n",
    "    number_of_heavy_vehicles = len(heavy_vehicles_first_year)\n",
    "    ådtt = number_of_heavy_vehicles / unique_days_in_range\n",
    "\n",
    "    return ådtt\n",
    "\n",
    "def calculate_factors(filepath: str, length_limit_1: float, length_limit_2: float)\\\n",
    "    -> Tuple[float, float, float, float, float, float, float, float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Samlefunksjon som hovedsakelig beregner N for gammel og ny lengdegrense for tunge kjøretøy.\n",
    "    Beregner videre endringen i N endringen i lengdegrensen fører med seg (absolutt og prosentvis endring).\n",
    "    Beregner videre B-faktor for begge lengdegrenser, samt endringen (absolutt og prosentvis endring).\n",
    "    Inkluderer ÅDTT for begge lengdegrenser, samt endringen (absolutt og prosentvis endring).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        Filstien til datasettet beregningene skal gjøres på.\n",
    "    length_limit_1: float\n",
    "        Første lengdegrense for tunge kjøretøy.\n",
    "    length_limit_2: flaot\n",
    "        Andre lengregrense for tunge kjøretøy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    N for første lengdegrense: float\n",
    "    N for andre lengdegrense: float\n",
    "    Absolutt endring av N ved overgang fra første til andre lengdegrense: float\n",
    "    Prosentvis endring av N ved overgang fra første til andre lengdegrense: float\n",
    "    ÅDTT for første lengdegrense: float\n",
    "    ÅDTT for andre lengdegrense: float\n",
    "    Absolutt endring av ÅDTT ved overgang fra første til andre lengdegrense: float\n",
    "    Prosentvis endring av ÅDTT ved overgang fra første til andre lengdegrense: float\n",
    "    B-faktor for første lengdegrense: float\n",
    "    B-faktor for andre lengdegrense: float\n",
    "    Absolutt endring av B-faktor ved overgang fra første til andre lengdegrense: float\n",
    "    Prosentvis endring av B-faktor ved overgang fra første til andre lengdegrense: float\n",
    "    \"\"\"\n",
    "\n",
    "    def calculate_factors_individual_lengthlimit(filepath: str, length_limit) -> Tuple[float, float, float]:\n",
    "        df = pl.read_csv(filepath, skip_rows=6, separator=';', truncate_ragged_lines=True, ignore_errors=True)\n",
    "        df = df.filter(pl.col(VEHICLE_LENGTH) >= length_limit)\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"StartTime\").cast(pl.Datetime(time_unit='ms')).alias('unix_timestamp')\n",
    "        )\n",
    "\n",
    "        earliest_date = df['unix_timestamp'].min().date().isoformat()\n",
    "        latest_date = df['unix_timestamp'].max().date().isoformat()\n",
    "\n",
    "        current_columns = df.columns\n",
    "        new_columns = [col.replace(' ', '') for col in current_columns]\n",
    "        df = df.clone() \n",
    "        df = df.with_columns(*[pl.col(col).alias(new_col) for col, new_col in zip(current_columns, new_columns)])\n",
    "        \n",
    "        ådtt = calculate_ådtt(df)\n",
    "        e, b = calculate_e_and_b(df)\n",
    "        c = calculate_c(df)\n",
    "        f = determine_f(filepath)\n",
    "        n = calculate_n(c, e, ådtt, f, P)\n",
    "\n",
    "        return n, ådtt, b, earliest_date, latest_date\n",
    "    \n",
    "    n_1, ådtt_1, b_1, startdate, enddate = calculate_factors_individual_lengthlimit(filepath, length_limit_1)\n",
    "    n_2, ådtt_2, b_2, _, _ = calculate_factors_individual_lengthlimit(filepath, length_limit_2)\n",
    "\n",
    "    absolute_change_n = n_2 - n_1\n",
    "    relative_change_n = ((n_2 - n_1) / n_1) * 100\n",
    "\n",
    "    absolute_change_ådtt = ådtt_2 - ådtt_1\n",
    "    relative_change_ådtt = ((ådtt_2 - ådtt_1) / ådtt_1) * 100\n",
    "\n",
    "    absolute_change_b = b_2 - b_1\n",
    "    relative_change_b = ((b_2 - b_1) / b_1) * 100\n",
    "\n",
    "    result = (\n",
    "        n_1, n_2, absolute_change_n, relative_change_n, \n",
    "        ådtt_1, ådtt_2, absolute_change_ådtt, relative_change_ådtt, \n",
    "        b_1, b_2, absolute_change_b, relative_change_b\n",
    "    )\n",
    "\n",
    "    result = tuple(round(value, 2) for value in result)\n",
    "\n",
    "    return startdate, enddate, *result\n",
    "\n",
    "def extract_location(filepath):\n",
    "    if 'Aanestad' in filepath and ('Vest' in filepath or 'vest' in filepath):\n",
    "        return 'Ånestad(vestgående)'\n",
    "    if 'Aanestad' in filepath and ('Ost' in filepath or 'ost' in filepath or 'Øst' in filepath or 'øst' in filepath):\n",
    "        return 'Ånestad(østgående)'\n",
    "    if 'Øysand' in filepath:\n",
    "        return 'Øysand'\n",
    "    if 'Skibotn' in filepath:\n",
    "        return 'Skibotn'\n",
    "    if 'Verdal' in filepath:\n",
    "        return 'Verdal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        \n",
    "        location = extract_location(dataset)\n",
    "\n",
    "        results.append((location, *calculate_factors(dataset, OLD_LIMIT_HEAVY_VEHICLE, NEW_LIMIT_HEAVY_VEHICLE)))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "headers = [\"Sted\", \"Startdato\", \"Sluttdato\", \"N 5.6\", \"N 7.5\", \"Absolutt endring i N\", \"Prosentvis endring i N\", \n",
    "           \"ÅDTT 5.6\", \"ÅDTT 7.5\", \"Absolutt endring i ÅDTT\", \"Prosentvis endring i ÅDTT\",\n",
    "            \"B-faktor 5.6\", \"B-faktor 7.5\", \"Absolutt endring i B-faktor\", \"Prosentvis endring i B-faktor\"]\n",
    "\n",
    "df = pl.DataFrame(schema=headers, data=results)\n",
    "df.write_csv('../resultater/n_påvirkning_klassifisering.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
